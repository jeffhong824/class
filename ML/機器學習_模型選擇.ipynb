{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aedda387-c7f5-42cf-9214-a39d6191f423",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ML "
   ]
  },
  {
   "cell_type": "raw",
   "id": "079a5ac9-c1af-442a-8b52-d8849ab62539",
   "metadata": {},
   "source": [
    "tot(場站總停車格)\n",
    "sbi(場站目前車輛數量)\n",
    "bemp(空位數量)\n",
    "act(全站禁用狀態)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4543d4ac-4655-43a8-9224-50fc405d892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import datasets, models, layers, utils, activations, losses, optimizers, metrics # DNN 系列\n",
    "from tensorflow.keras.layers import Dense, LSTM,Bidirectional,SimpleRNN,GRU,Activation # RNN系列\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_score,recall_score,f1_score\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21542e2b-f466-404d-b186-0c33f4c0aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input path\n",
    "project_path = 'D:/在職進修/修課/機器學習/Final_project/'\n",
    "release_path = project_path+'html.2023.final.data-release/release/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e65407b-f3b3-487a-b65b-7a6d7b358c44",
   "metadata": {},
   "source": [
    "#### 特徵工程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6a0a41-2a9a-45d3-b257-952088e8ea99",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### feature1_day\n",
    "* feature\n",
    "    * Station characteristics * 1\n",
    "    * Station upper bound * 1\n",
    "    * date characteristics * 2 (星期、放假)\n",
    "    * time characteristics * 3 (小時、分鐘、累積)\n",
    "    * 1 day time step 72 * 1\n",
    "* --> input 72 * 8\n",
    "* --> pred 72 * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248b3d92-c9a8-4b56-a602-00f54609dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_phase2 = project_path+'data_science_phase2_feature/feature1_day/'\n",
    "\n",
    "X_train = np.load(save_path_phase2+'X_train.npy') \n",
    "y_train = np.load(save_path_phase2+'y_train.npy') \n",
    "X_test = np.load(save_path_phase2+'X_test_target_sno.npy') \n",
    "y_test = np.load(save_path_phase2+'y_test_target_sno.npy') \n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape \n",
    "\n",
    "X_test_sampled = X_test[::20, :, :]\n",
    "y_test_sampled = y_test[::20, :, :]\n",
    "\n",
    "X_test_sampled.shape, y_test_sampled.shape \n",
    "\n",
    "time_steps = 72 # 根据您的数据设置时间步\n",
    "features = 8 # 特征数量\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], time_steps, features))\n",
    "y_train_reshaped = y_train.reshape((y_train.shape[0], time_steps, features))\n",
    "X_test_reshaped = X_test_sampled.reshape((X_test_sampled.shape[0], time_steps, features))\n",
    "y_test_reshaped = y_test_sampled.reshape((y_test_sampled.shape[0], time_steps, features))\n",
    "\n",
    "ratio = X_test_reshaped.shape[0] / X_train_reshaped.shape[0]\n",
    "\n",
    "X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(X_train_reshaped, y_train_reshaped, test_size=ratio)\n",
    "\n",
    "y_train_train = y_train_train[:, :, -1:]\n",
    "y_train_val = y_train_val[:, :, -1:]\n",
    "y_test_reshaped = y_test_reshaped[:, :, -1:]\n",
    "\n",
    "X_train_train.shape, y_train_train.shape, X_train_val.shape, y_train_val.shape, X_test_reshaped.shape, y_test_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00542abd-b1cf-43e7-b285-9243a613b847",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c686b873-1c94-4f91-8983-39465d776ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, losses, optimizers\n",
    "\n",
    "num_outputs = 72  # 回归模型的输出维度通常是\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(\n",
    "    units=50,\n",
    "    input_shape=(time_steps, features),  # time_steps, features\n",
    "    unroll=True,\n",
    "))\n",
    "model.add(layers.Dense(units=num_outputs, kernel_initializer='normal'))  # 无激活函数\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# 设置训练\n",
    "model.compile(loss=losses.mean_squared_error,  # 回归任务常用的损失函数\n",
    "              optimizer='adam',  # 优化器\n",
    "              metrics=['mean_squared_error']  # 评估指标\n",
    "              )\n",
    "\n",
    "Batch_size = 128\n",
    "Epochs = 5\n",
    "filepath = save_path_phase2+\"model/LSTM_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_mean_squared_error', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "callbacks_list = [checkpoint]\n",
    "logs = model.fit(X_train_train, y_train_train, batch_size=Batch_size, epochs=Epochs, validation_data=(X_train_val, y_train_val), callbacks=callbacks_list)\n",
    "# filepath = save_path_phase2+\"model/LSTM_weights.hdf5\"\n",
    "# model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb5fa3-f0f3-4c9f-bf95-84d5d63feb18",
   "metadata": {},
   "source": [
    "## Dropout LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af82be77-b7f1-4aa1-928a-22579530b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, losses, optimizers, regularizers\n",
    "\n",
    "time_steps = 72  # 假設您的時間步長為72\n",
    "features = 8  # 假設您有8個特徵\n",
    "num_outputs = 72  # 輸出維度\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(\n",
    "    units=50,\n",
    "    input_shape=(time_steps, features),\n",
    "    unroll=True,\n",
    "    dropout=0.25,  # 加入 dropout\n",
    "    recurrent_dropout=0.25  # 加入 recurrent dropout\n",
    "))\n",
    "model.add(layers.Dense(\n",
    "    units=num_outputs, \n",
    "    kernel_initializer='normal',\n",
    "    kernel_regularizer=regularizers.l2(0.01)  # 加入 L2 正則化\n",
    "))\n",
    "model.add(layers.Dropout(0.5))  # 在 Dense 層後加入額外的 Dropout 層\n",
    "\n",
    "# 設定模型訓練\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,  # 使用均方誤差作為損失函數\n",
    "    optimizer='adam',\n",
    "    metrics=['mean_squared_error']\n",
    ")\n",
    "\n",
    "Batch_size = 128\n",
    "Epochs = 5\n",
    "filepath = save_path_phase2+\"model/LSTM_dropout_recurrent_dropout_regularizers_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_mean_squared_error', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "callbacks_list = [checkpoint]\n",
    "logs = model.fit(X_train_train, y_train_train, batch_size=Batch_size, epochs=Epochs, validation_data=(X_train_val, y_train_val), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b386efe-0a64-48a0-982a-dc256f0fddcf",
   "metadata": {},
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ddb27c26-61e9-4515-b065-7fd86cf502cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13771/13771 [==============================] - 1995s 143ms/step - loss: 0.0488 - mean_squared_error: 0.0488 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from inf to 0.04612, saving model to D:/在職進修/修課/機器學習/Final_project/data_science_phase2_feature/feature1_day/model\\BiLSTM_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers, losses, optimizers\n",
    "\n",
    "num_outputs = 72  # 回归模型的输出维度\n",
    "\n",
    "# 定义模型\n",
    "model = models.Sequential()\n",
    "model.add(layers.Bidirectional(layers.LSTM(\n",
    "    units=50,\n",
    "    input_shape=(time_steps, features),  # time_steps, features\n",
    "    unroll=True\n",
    ")))\n",
    "model.add(layers.Dense(units=num_outputs, kernel_initializer='normal'))  # 无激活函数\n",
    "\n",
    "\n",
    "# 设置训练\n",
    "model.compile(loss=losses.mean_squared_error,  # 回归任务常用的损失函数\n",
    "              optimizer='adam',  # 优化器\n",
    "              metrics=['mean_squared_error']  # 评估指标\n",
    "              )\n",
    "\n",
    "Batch_size = 128\n",
    "Epochs = 1\n",
    "filepath = save_path_phase2+\"model/BiLSTM_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_mean_squared_error', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "callbacks_list = [checkpoint]\n",
    "logs = model.fit(X_train_train, y_train_train, batch_size=Batch_size, epochs=Epochs, validation_data=(X_train_val, y_train_val), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1aa61b-c1e1-495b-b976-689f8f3082b6",
   "metadata": {},
   "source": [
    "## Finetuned-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2677e50-7327-4cac-9d88-c63f1f033767",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 確認主要想預測的 sno\n",
    "def collect_target_sno(_path):\n",
    "    '''\n",
    "    Readme\n",
    "    \n",
    "    > input:\n",
    "        _path # 提交格式csv檔案路徑\n",
    "    \n",
    "    > output\n",
    "        target_sno # 提交csv所需sno\n",
    "    \n",
    "    '''\n",
    "    sample_csv = pd.read_csv(_path)\n",
    "    target_sno = {each.split('_')[1] for each in sample_csv['id']}\n",
    "    print('finish target_sno: ', len(target_sno)) # 期望數量\n",
    "    return list(target_sno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b672d1e8-7981-4094-a335-6708e1d16236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish target_sno:  112\n"
     ]
    }
   ],
   "source": [
    "# input path\n",
    "project_path = 'D:/在職進修/修課/機器學習/Final_project/'\n",
    "release_path = project_path+'html.2023.final.data-release/release/'\n",
    "sample_csv_list = ['sample_submission_stage'+str(eg) for eg in range(1,4)]\n",
    "\n",
    "# collect_target_sno\n",
    "target_sno = collect_target_sno(project_path+sample_csv_list[0]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0288921-307d-453b-8a6a-2c613b4461f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7eeba0f-d123-4e6a-8024-64a8c9d36404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 112/112 [27:02<00:00, 14.49s/it]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "for sno in tqdm(target_sno):\n",
    "    filepath = save_path_phase2+\"model/finetune/LSTM_weights_\"+sno+\".hdf5\"\n",
    "    try:\n",
    "        model.load_weights(filepath)\n",
    "    except:\n",
    "        model.load_weights(save_path_phase2+\"model/LSTM_weights.hdf5\")\n",
    "        \n",
    "    X_train_one = np.load(save_path_phase2+sno+'_X_train.npy') \n",
    "    y_train_one = np.load(save_path_phase2+sno+'_y_train.npy') \n",
    "\n",
    "    time_steps = 72 # 根据您的数据设置时间步\n",
    "    features = 8 # 特征数量\n",
    "    X_train_one_reshaped = X_train_one.reshape((X_train_one.shape[0], time_steps, features))\n",
    "    y_train_one_reshaped = y_train_one.reshape((y_train_one.shape[0], time_steps, features))\n",
    "    y_train_one_reshaped = y_train_one_reshaped[:, :, -1:]\n",
    "\n",
    "    X_train_one_reshaped_train, X_train_one_reshaped_val, y_train_one_reshaped_train, y_train_one_reshaped_val =  X_train_one_reshaped[:60] , X_train_one_reshaped[60:], y_train_one_reshaped[:60] , y_train_one_reshaped[60:]\n",
    "\n",
    "    Batch_size = 128\n",
    "    Epochs = 50\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_mean_squared_error', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "    callbacks_list = [checkpoint]\n",
    "    logs = model.fit(X_train_one_reshaped_train, y_train_one_reshaped_train, batch_size=Batch_size, epochs=Epochs, validation_data=(X_train_one_reshaped_val, y_train_one_reshaped_val), callbacks=callbacks_list)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d90a72b-efa7-42df-86d8-f0fd3769a243",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be4b9c49-d942-4669-b472-763ecdae62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC,SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "STEPS = []\n",
    "PCA_threshold = True  # 假设您有一些逻辑来决定是否使用 PCA\n",
    "Normalizer_threshold = False  # 同上，对于 Normalizer\n",
    "\n",
    "# 假设 pca 和 normalizer 已经被定义\n",
    "pca = PCA(n_components = 10)\n",
    "normalizer = Normalizer()\n",
    "\n",
    "if PCA_threshold:\n",
    "    STEPS.append(('pca', pca))\n",
    "elif Normalizer_threshold:\n",
    "    STEPS.append(('normalizer', normalizer))\n",
    "\n",
    "Seed = 7\n",
    "cv_train = 5\n",
    "svr = SVR(C=100, gamma=0.1, tol=0.001, kernel='rbf')\n",
    "lr = LinearRegression()\n",
    "# STEPS.append(('svr', svr))\n",
    "\n",
    "\n",
    "ML_model = Pipeline(steps=STEPS)\n",
    "\n",
    "# 將 SVR 包裝在 MultiOutputRegressor 中\n",
    "multioutput_regressor = MultiOutputRegressor(SVR(C=100, gamma=0.1, tol=0.0000001, kernel='rbf'))\n",
    "# multioutput_regressor = MultiOutputRegressor(lr())\n",
    "STEPS.append(('multioutput_regressor',multioutput_regressor))\n",
    "# ML_model = Pipeline(steps=[('pca', pca),('normalizer', normalizer), ('multi_svr', multioutput_regressor)])\n",
    "ML_model = Pipeline(steps=STEPS) \n",
    "\n",
    "# parameters = {}\n",
    "#parameters['pca__n_components'] = [10,20,30]  \n",
    "parameters = {\n",
    "    'pca__n_components' : [10,20,30],\n",
    "    # 'multioutput_regressor__estimator__gamma': [0.1,1],\n",
    "    # 'multioutput_regressor__estimator__C': [10,100],\n",
    "}\n",
    "tuned_parameters = [parameters]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab850c23-3538-4eaf-ad52-3f1c6e372800",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_model\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "y_train_ml = y_train[:, :, -1:]\n",
    "\n",
    "y_train_ml.shape\n",
    "\n",
    "X_train_ml = X_train.reshape((X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
    "y_train_ml = y_train_ml.reshape((y_train_ml.shape[0], y_train_ml.shape[1]*y_train_ml.shape[2]))\n",
    "\n",
    "X_train_ml.shape, y_train_ml.shape\n",
    "\n",
    "## ML_model.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# random_search = RandomizedSearchCV(ML_model, parameters, cv=5, scoring=custom_scorer, verbose=2, n_iter=10, random_state=42)\n",
    "random_search = RandomizedSearchCV(ML_model, parameters, cv=5, scoring='neg_mean_squared_error', verbose=2, n_iter=10, random_state=42)\n",
    "\n",
    "# random_search.fit(data_feature_normalize, labels)\n",
    "random_search.fit(X_train_ml, y_train_ml)\n",
    "best_model = random_search.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
